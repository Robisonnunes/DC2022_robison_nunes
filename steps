DATASETS
Dados originais estão na pasta Dados_etc/, todos os outros estão na raiz

portfolio_full = p_geral + p_comunicados + p_cliente + p_ptv + indices_por_uf_ibge

caminho df = portfolio_full > df > df_efetividade > df_clusterizada - df0
                                                                    - df1
                                                                    - df2 
Transformações no df = filro sazonalidade 
                  df = df1 só linhas com acoes

--------------------------------------------------------------------------------------------------------------------------------------------
1 -  BUSINESS UNDERSTANDING 
Nesa primeira etapa o objetivo e entender o contexto dos dados e entender também qual pergunta de negócio tenha que responder com análise de dados

2 -  DATA UNDERSTANDING
Processo de entendimento dos arquivos de dados de forma separada e através do diagrama MER entender o relacionamento entre as tabelas

	2.1 -  LOAD DATASETS
	Carregamento e visualização dos dados de cada base 

	2.2 -  EXPLORATORY DATA ANALYSIS
	Nesta etapa fiz um overview das metricas básicas sobre os datasets, Ex: shape, missing, duplicated 
	
3 - ETL
Etapa fundamental aqui fiz todos os arranjos e transformações em cada dataset com o objetivo de criar uma base única, com todas as dimensões do problema a ser resolvido.

Ex: criação de chaves únicas, agrupamentos, label encoding, remoção de linhas duplicadas, exportação de outputs de cada dataset

	3.1 -  PORTIFÓLIO COMUNICADOS
	Apos a analise do dataset comunicados, decidi agrupar todas as informacoes de ação e status em uma linha só, antes cada tipo de acao
	ocupava uma linha e o contrato_id nao era um indexador único, criei entao uma PK com a uniao do contrato_id + dt_ref_portfolio, 
	criando uma chave para o 	merge com portifolio geral.

	3.2 -  PORTIFÓLIO TPV			
	Apos a analise do dataset, corrigi o formato da data e criei uma PK com a uniao do 'nr_documento' + 'dt_transacao', 
	criando uma chave para o merge com portifolio geral.
	
	3.3 -  PORTIFÓLIO CLIENTES
	Apos a analise do dataset, removi as linhas duplicadas
	
	3.4 -  CRIACAO DA BASE ÚNICA
	Foi feito o carregamentos dos resultados dos etls das bases de comunicados/tpv/clientes para fazer o join com portifolio geral
	gerando assim a base única, foram feito os seguintes passsos:
	
	- Criação de chaves estrageiras das tabelas dimensão no portofolio geral 
	- foi feitos os joins separadamente
	- rename das colunas e drop das colunas desnecessárias 
	- exportação do output do etl geral para proxima parte de análise
	
	3.5 -  ENRIQUECIMENTO COM FONTES EXTERNAS
	- foram eliminadas as colunas UF e código
	- Correção dos tipos de dados 
	- Feito o Join com o dataset df
	- foi exportado o 1º data point
	
4 - DATA ANALYSIS
Foi feito o carregamento da base de dados resultante do Etl abaixo:
portfolio_full = p_geral + p_comunicados + p_cliente + p_ptv + indices_por_uf_ibge 

    4.1 - MÉTRICAS (BASE LINE)
    - O objetivo aqui é encontrar os parâmetros de controle para os insights
    
    	4.1.1 - Curva de sazionalidade por data de transacao (portifolio tpv)
    	- Aqui eu gerei um gráfico com o objetivo de encotrar a curva de sazonalidade e escolher o melhor intervalo de dados para se 
    	gerar insights olhando para o cenário futuro mais aproximado desse intervalo de dados
    	- Após essa análise o novo df estará filtrado no seguinte espaco de tempo 19-10-2021 a 19-04-2022, mesmo que os dados de tpv 
    	nao comteplam esse período espera -se um comportamento acima do mesmo período de 2021.
    	
    	4.1.2 - Agrupamentos e filtros da base somente linhas com acao
    	- Aqui foi filtrado gerando o df1 para extrair as métricas de campanhas 
    	
    	4.1.3 - Gráfico engajamento por canal
    	-Esse gráfico mostra de maneira geral como está o engajamento por todas as açoes por email e hsm
    	
    	4.1.4 - Gráfico Geral de engajamento por canal e tipo de ação
        -Esse gráfico mostra de maneira geral como está o engajamento por tipo de ação nas canais de email e hsm
        
        4.1.5 - rankinq geral de dsp/dspp por segmento/tipo de empresa
        - Esse gráfico mostra o ranking 
        
	4.1.6 - Criação da janelas de efetividade das ações
	- Nessa eu fiz dois grandes loops com o ojetivo de criar duas colunas importantes para minha análise a efetividade e acao2
	- efetividade - irá informar se houve pagamento apos um acao ter sido lida e estiver na sua janela de tempo ex: acao
	 observacao tem uma janela de 5 dias
	- acao 2 - irá indeficar quais acoes com base no dsp e dspp
	
	4.1.7 - gráfico de efetividade de pagamento
	- Sao dois grádicos que serao a base line para análise futura da base em clusters 
	- Curva de efetividade por acionamentos x efetividade da acao
	- Curva de efetividade por acao

   4.2 -  CLUSTERIZAÇÃO DA BASE
   O objetivo aqui foi encontrar insights para diferentes tipos de clientes por meio de um algoritmo de machine learning de clusterizaçao
   O Kmeans. doi selecionado as variaveis relevantes para essa acao.
   
       4.2.1 - Gráfico de Elbon - Kmeans
       - Grádico de Elbom ele mostra o nº de cluster ideal (hiperparemetro do modelo)
       - Através do gráfico foi definido que 3 clusters seria o ideal para a nossa análise
       
       4.2.2 - Construindo e Treinando o Modelo - Kmeans
       - Aplicando os hiperametros necessários e cronstruindo o modelo
       - Foi feito o treinamento do modelo
       - Após o treinamento fois extraídos e atribuido a um objeto as labels dos rótulos
       - Foi feito o objeto cluster (dim da base clusterizada) e foi feito um join com as labels) (contrao_id (PK) e labels)
       
       4.2.2 - Construindo base cluserizada - Kmeans
       - foi feito o join da base df + cluster para atribuir um tag de cluster em toda a base
       - Após isso a base foi dividida em 3 clusters
       
       4.2.3 - Cluser 0 - Kmeans
       - foram criadas todas as bases para gerar dois gráficos que analisa dois aspectos
       - - Curva de efetividade por acionamentos x efetividade da acao
	- Curva de efetividade por acao
       
       4.2.4 - Cluser 1 - Kmeans
       - foram criadas todas as bases para gerar dois gráficos que analisa dois aspectos
       - - Curva de efetividade por acionamentos x efetividade da acao
	- Curva de efetividade por acao
       
       4.2.5 - Cluser 2 - Kmeans
       - foram criadas todas as bases para gerar dois gráficos que analisa dois aspectos
       - - Curva de efetividade por acionamentos x efetividade da acao
	- Curva de efetividade por acao
       
5 -  INSIGHTS
Nessa secao apresento todo resultado de análise exploratório de dados com também a recomendacao de análise para a melhor curva
de efetividade da acao.
       
       Conte pra nós, qual é a curva ideal de vezes que devemos acionar um cliente?

A estratégia usada foi principalmente feita em python e uma análise complementar visual em Power Bi, importante ressaltar que as duas análises se complementar nao dizem a mesma coisa , obejtivo foi clusterizar a base e responder a pergunta de negócio.

Iniciei fazendo uma análise de exploratóra dos dados e preparando as bases para fazer uma base única e ainda acresentei fonte externas do IBGE tendo com chave o estado na base de clientes , a cidade que seria mais proveitoso apresentava inconsistencias e gerei base única.



       
   	
	
	
	
